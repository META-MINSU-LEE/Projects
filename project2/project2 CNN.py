# -*- coding: utf-8 -*-
"""230608CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u035yx3bBAKxdbFt_CIuYQdM6YNFjZYV
"""

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Mount Google Drive to access the dataset
from google.colab import drive
drive.mount('/content/drive')

# Path to the folders containing the images
Double_path = '/content/drive/MyDrive/Double'
Kog_path = '/content/drive/MyDrive/Kog'

# Parameters
image_size = (64, 64)
batch_size = 32

# Data augmentation and preprocessing
train_datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

test_datagen = ImageDataGenerator(rescale=1.0/255.0)

# Load and preprocess the training set
train_set = train_datagen.flow_from_directory(
    Double_path,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='binary'
)

# Load and preprocess the test set
test_set = test_datagen.flow_from_directory(
    Kog_path,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='binary'
)

# Create the CNN model
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(
    train_set,
    steps_per_epoch=train_set.samples // batch_size,
    epochs=100,
    validation_data=test_set,
    validation_steps=test_set.samples // batch_size
)



